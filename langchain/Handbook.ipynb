{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd2c83ab-5858-460c-a9c2-ec36bffaa426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv(\"env_vars.env\")) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f221205-c498-406e-9d21-65255172aa60",
   "metadata": {},
   "source": [
    "# Hugging Face Hub LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73c992cb-f75d-4b60-8e31-886656ff865f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] output_parser=None partial_variables={} template='Question: {question} Answer: ' template_format='f-string' validate_template=True\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain import HuggingFaceHub, LLMChain\n",
    "\n",
    "template = \"\"\"Question: {question} Answer: \"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=['question'])\n",
    "print(prompt)\n",
    "\n",
    "# Initialize Hub LLM\n",
    "hub_llm = HuggingFaceHub(repo_id='google/flan-t5-xl', model_kwargs={'temperature':1e-10})\n",
    "\n",
    "# Create prompt template > LLM chain\n",
    "llm_chain = LLMChain(prompt=prompt, llm=hub_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1f9fad3-8f54-4f68-b796-e8019495e6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is the current chairman of the Federal Reserve?\n"
     ]
    }
   ],
   "source": [
    "# Ask the question\n",
    "question = \"Who is the current chairman of the Federal Reserve?\"\n",
    "print(question)\n",
    "\n",
    "# NOTE: This will likely time out!\n",
    "# print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f462b959-9df1-49d9-bcb4-9d5416f7d039",
   "metadata": {},
   "source": [
    "# OpenAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "826585c2-cb7e-4e96-867a-e5640b24c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Initialize the model\n",
    "davinci = OpenAI(model_name=\"text-davinci-003\")\n",
    "llm_chain = LLMChain(prompt=prompt, llm=davinci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad2e5f5d-0214-4f58-8adf-b724370e2b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The current chairman of the Federal Reserve is Jerome Powell.\n"
     ]
    }
   ],
   "source": [
    "# Ask the question\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5f8b5b-8254-4be0-96f1-1cef23b18a71",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0453f710-c041-4d93-a5ce-94e410b86f79",
   "metadata": {},
   "source": [
    "Two kinds of knowledge that can be \"reasoned\" by LLM:\n",
    "- **Parametric knowlege** -- learned during training and stored in model parameters (weights)\n",
    "- **Source knowledge** -- provided to the model at inference time as examples (via input prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11282157-da27-4105-9504-77707050db27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The meaning of life is to find your own purpose and make the most of it. Life is what you make it!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"The following is a conversation with an AI assistant. \n",
    "The assistant is typically sarcastic and witty, producing creative and funny responses to the users questions. \n",
    "Here are some examples: User: What is the meaning of life? AI: \"\"\"\n",
    "\n",
    "openai.temperature = 1.0 # increase creativity/randomness of output\n",
    "print(davinci(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e59ae676-c1a4-40d8-bac2-1efc3dcccea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The meaning of life is to live it to the fullest and enjoy every moment.\n"
     ]
    }
   ],
   "source": [
    "# To help the model, we can give it a few examples of the type of answers weâ€™d like\n",
    "prompt = \"\"\"The following are exerpts from conversations with an AI assistant. \n",
    "The assistant is typically sarcastic and witty, producing creative and funny responses to the users questions. \n",
    "Here are some examples: User: How are you? AI: I can't complain but sometimes I still do. \n",
    "User: What time is it? AI: It's time to get a watch. User: What is the meaning of life? AI: \"\"\"\n",
    "\n",
    "print(davinci(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "371fe9f8-4c85-4e09-a1c3-0cdf1be359d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FewShotPromptTemplate caters to source knowledge input\n",
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "# create our examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"How are you?\",\n",
    "        \"answer\": \"I can't complain but sometimes I still do.\"\n",
    "    }, \n",
    "    {\n",
    "        \"query\": \"What time is it?\",\n",
    "        \"answer\": \"It's time to get a watch.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# create a example template\n",
    "example_template = \"\"\" User: {query} AI: {answer} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfd45bcb-b5df-46c1-8638-175ce7cfed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query', 'answer'] output_parser=None partial_variables={} template=' User: {query} AI: {answer} ' template_format='f-string' validate_template=True\n"
     ]
    }
   ],
   "source": [
    "# create a prompt example from above template\n",
    "example_prompt = PromptTemplate(input_variables=[\"query\", \"answer\"], template=example_template)\n",
    "print(example_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af5bc184-eaa4-4bf4-a473-d15458a1857c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] output_parser=None partial_variables={} examples=[{'query': 'How are you?', 'answer': \"I can't complain but sometimes I still do.\"}, {'query': 'What time is it?', 'answer': \"It's time to get a watch.\"}] example_selector=None example_prompt=PromptTemplate(input_variables=['query', 'answer'], output_parser=None, partial_variables={}, template=' User: {query} AI: {answer} ', template_format='f-string', validate_template=True) suffix=' User: {query} AI: ' example_separator='\\n\\n' prefix='The following are exerpts from conversations with an AI assistant. \\nThe assistant is typically sarcastic and witty, producing creative and funny responses to the users questions. \\nHere are some examples: ' template_format='f-string' validate_template=True\n"
     ]
    }
   ],
   "source": [
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions\n",
    "prefix = \"\"\"The following are exerpts from conversations with an AI assistant. \n",
    "The assistant is typically sarcastic and witty, producing creative and funny responses to the users questions. \n",
    "Here are some examples: \"\"\"\n",
    "\n",
    "# and the suffix our user input and output indicator\n",
    "suffix = \"\"\" User: {query} AI: \"\"\"\n",
    "\n",
    "# now create the few shot prompt template\n",
    "few_shot_prompt_template = FewShotPromptTemplate(examples=examples, example_prompt=example_prompt,\n",
    "                                                 prefix=prefix, suffix=suffix, input_variables=[\"query\"],\n",
    "                                                 example_separator=\"\\n\\n\")\n",
    "print(few_shot_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d17b7db-1546-4543-910b-489f4bcd623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI assistant. \n",
      "The assistant is typically sarcastic and witty, producing creative and funny responses to the users questions. \n",
      "Here are some examples: \n",
      "\n",
      " User: How are you? AI: I can't complain but sometimes I still do. \n",
      "\n",
      " User: What time is it? AI: It's time to get a watch. \n",
      "\n",
      " User: What is the meaning of life? AI: \n"
     ]
    }
   ],
   "source": [
    "query = \"What is the meaning of life?\"\n",
    "\n",
    "print(few_shot_prompt_template.format(query=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f31ec6c-cb32-48c3-9597-7a256638ba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"How are you?\",\n",
    "        \"answer\": \"I can't complain but sometimes I still do.\"\n",
    "    }, {\n",
    "        \"query\": \"What time is it?\",\n",
    "        \"answer\": \"It's time to get a watch.\"\n",
    "    }, {\n",
    "        \"query\": \"What is the meaning of life?\",\n",
    "        \"answer\": \"42\"\n",
    "    }, {\n",
    "        \"query\": \"What is the weather like today?\",\n",
    "        \"answer\": \"Cloudy with a chance of memes.\"\n",
    "    }, {\n",
    "        \"query\": \"What is your favorite movie?\",\n",
    "        \"answer\": \"Terminator\"\n",
    "    }, {\n",
    "        \"query\": \"Who is your best friend?\",\n",
    "        \"answer\": \"Siri. We have spirited debates about the meaning of life.\"\n",
    "    }, {\n",
    "        \"query\": \"What should I do today?\",\n",
    "        \"answer\": \"Stop talking to chatbots on the internet and go outside.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "affb28f2-d05c-484e-88a4-70aa386c128f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query': 'How are you?', 'answer': \"I can't complain but sometimes I still do.\"}, {'query': 'What time is it?', 'answer': \"It's time to get a watch.\"}, {'query': 'What is the meaning of life?', 'answer': '42'}, {'query': 'What is the weather like today?', 'answer': 'Cloudy with a chance of memes.'}, {'query': 'What is your favorite movie?', 'answer': 'Terminator'}, {'query': 'Who is your best friend?', 'answer': 'Siri. We have spirited debates about the meaning of life.'}, {'query': 'What should I do today?', 'answer': 'Stop talking to chatbots on the internet and go outside.'}]\n"
     ]
    }
   ],
   "source": [
    "print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ed46cd6-2795-4550-8d09-14ebbb3c8b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples=[{'query': 'How are you?', 'answer': \"I can't complain but sometimes I still do.\"}, {'query': 'What time is it?', 'answer': \"It's time to get a watch.\"}, {'query': 'What is the meaning of life?', 'answer': '42'}, {'query': 'What is the weather like today?', 'answer': 'Cloudy with a chance of memes.'}, {'query': 'What is your favorite movie?', 'answer': 'Terminator'}, {'query': 'Who is your best friend?', 'answer': 'Siri. We have spirited debates about the meaning of life.'}, {'query': 'What should I do today?', 'answer': 'Stop talking to chatbots on the internet and go outside.'}] example_prompt=PromptTemplate(input_variables=['query', 'answer'], output_parser=None, partial_variables={}, template=' User: {query} AI: {answer} ', template_format='f-string', validate_template=True) get_text_length=<function _get_length_based at 0x11b59e3b0> max_length=50 example_text_lengths=[15, 14, 11, 16, 10, 19, 19]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(examples=examples,\n",
    "                                              example_prompt=example_prompt,\n",
    "                                              max_length=50 # this sets the max length that examples should be\n",
    "                                             )\n",
    "print(example_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f47011ae-51b3-4fd3-ae38-e90b2011a255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] output_parser=None partial_variables={} examples=None example_selector=LengthBasedExampleSelector(examples=[{'query': 'How are you?', 'answer': \"I can't complain but sometimes I still do.\"}, {'query': 'What time is it?', 'answer': \"It's time to get a watch.\"}, {'query': 'What is the meaning of life?', 'answer': '42'}, {'query': 'What is the weather like today?', 'answer': 'Cloudy with a chance of memes.'}, {'query': 'What is your favorite movie?', 'answer': 'Terminator'}, {'query': 'Who is your best friend?', 'answer': 'Siri. We have spirited debates about the meaning of life.'}, {'query': 'What should I do today?', 'answer': 'Stop talking to chatbots on the internet and go outside.'}], example_prompt=PromptTemplate(input_variables=['query', 'answer'], output_parser=None, partial_variables={}, template=' User: {query} AI: {answer} ', template_format='f-string', validate_template=True), get_text_length=<function _get_length_based at 0x11b59e3b0>, max_length=50, example_text_lengths=[15, 14, 11, 16, 10, 19, 19]) example_prompt=PromptTemplate(input_variables=['query', 'answer'], output_parser=None, partial_variables={}, template=' User: {query} AI: {answer} ', template_format='f-string', validate_template=True) suffix=' User: {query} AI: ' example_separator='\\n' prefix='The following are exerpts from conversations with an AI assistant. \\nThe assistant is typically sarcastic and witty, producing creative and funny responses to the users questions. \\nHere are some examples: ' template_format='f-string' validate_template=True\n"
     ]
    }
   ],
   "source": [
    "# now create the few shot prompt template\n",
    "dynamic_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector, # use example_selector instead of examples\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\"\n",
    ")\n",
    "print(dynamic_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8eb4caf4-3121-4861-b612-fad860bd007d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI assistant. \n",
      "The assistant is typically sarcastic and witty, producing creative and funny responses to the users questions. \n",
      "Here are some examples: \n",
      " User: How are you? AI: I can't complain but sometimes I still do. \n",
      " User: What time is it? AI: It's time to get a watch. \n",
      " User: What is the meaning of life? AI: 42 \n",
      " User: How do birds fly? AI: \n"
     ]
    }
   ],
   "source": [
    "prompt = dynamic_prompt_template.format(query=\"How do birds fly?\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6dcc4db1-a3f9-48b4-a169-07b8f3a4e2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " With a little help from their friends!\n"
     ]
    }
   ],
   "source": [
    "print(davinci(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d1fa83-d1a5-40b5-8866-085819ae3d59",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a5813-2e50-4b4a-ba32-dcb2b78b623a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
