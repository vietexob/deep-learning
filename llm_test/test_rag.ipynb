{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def4d690-6f97-4c1b-bf58-195242310d35",
   "metadata": {},
   "source": [
    "## RAG Demo Using Offline Docs\n",
    "\n",
    "### Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020727ec-86ce-4c5a-a962-4a18451b64bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv(\"env_vars.env\")) # read local .env file\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea2084c-2d5b-4d72-92fb-89c9c52c6589",
   "metadata": {},
   "source": [
    "### Load the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0ea9d8-89ce-4f9c-8a4b-16fc93554c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loaders = [PyPDFLoader(\"../docs/Inview_June_2023.pdfInview_June_2023.pdf\")]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "    \n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e239bcb-376f-4020-afee-714406f83d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# Split into chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(len(splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f02cd-3a11-4d94-a32a-a1fd24281643",
   "metadata": {},
   "source": [
    "### Store \"chunks\" as vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a4aae2d-e323-4115-be0f-e4a137c7e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The embedding libraries\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "persist_directory = '../docs/chroma-test/'\n",
    "!rm -rf ../docs/chroma-test/  # remove old database files if any\n",
    "\n",
    "# # OpenAI embedding\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# # Try a different embedding (HF)\n",
    "# embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "# Try a different embedding (ST)\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "606e69e6-5ef5-40e8-9c2e-243e6d2c626b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# Store in the local vector DB\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda8f59-7935-4f5c-a1ba-ee07f56629cb",
   "metadata": {},
   "source": [
    "### Semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a5c81e1-6bd1-48d7-9f00-0c8b646014ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "question = \"What industry sectors are recommended for stocks?\"\n",
    "\n",
    "docs = vectordb.similarity_search(question, k=3)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "140d23e6-b7e1-4ff7-ac3e-0ba430e8e53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Inview June 2023   |  05Alternatives\\nALTERNATIVES\\n↔ • Hedge Fund\\nReal Assets• Private Markets\\nCommodity\\nInsurance•\\n•\\n•↔\\n↔\\n↔\\n↔Weighting\\nchange from\\nlast month\\n– Underweight  + Overweight  • Neutral \\n↔ No change ↑ Increase ↓ DecreaseAllocation\\nversus the\\nbenchmarkASSET ALLOCATION\\nEquity Sector Views (cont.)\\nUS\\nWe remain cautious given the macroeconomic uncertainties \\nand so choose not to take any large sector bets at this time. \\nInstead, focus is on individual company earnings resilience \\nfrom a bottom-up perspective. We are underweight cyclical \\nsectors where there is an unfavourable risk-reward profile, \\nsuch as banks, heavy industrials and real estate. There have \\nbeen selective additions to exposure in areas that were first \\nimpacted by the downturn and subsequently likely to be the \\nfirst to recover, including semiconductors, digital advertising \\nand housing.  \\nAsia ex-Japan\\nWe maintain our overweight position in Asia ex-Japan. Within \\nthe region we maintain a relatively small overweight to \\nChina, where there is patchy economic recovery momentum \\nbut an improvement in earnings expectations. We are neutral \\non India, where economic momentum is robust. We note that \\nthere is particular strength in property as well as public and \\nprivate capital expenditure, while there has been some \\nconsumer weakening. Within IT, the cycle has likely bottomed \\nin areas such as memory, but other areas remain in a \\ndowntrend.\\nNo changes were made to our alternatives exposure this'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the top-ranked result\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bfc318a-8764-45d6-b105-5bbf51564110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 4, 'source': '../docs/Inview_June_2023.pdfInview_June_2023.pdf'}\n",
      "{'page': 3, 'source': '../docs/Inview_June_2023.pdfInview_June_2023.pdf'}\n",
      "{'page': 4, 'source': '../docs/Inview_June_2023.pdfInview_June_2023.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ca13c49-6cd2-4be2-8226-83f6091232a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + \n",
    "                                   d.page_content for i, d in enumerate(docs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6656eccd-e982-4b3b-b3a7-4a0b72bcfbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Inview June 2023   |  05Alternatives\n",
      "ALTERNATIVES\n",
      "↔ • Hedge Fund\n",
      "Real Assets• Private Markets\n",
      "Commodity\n",
      "Insurance•\n",
      "•\n",
      "•↔\n",
      "↔\n",
      "↔\n",
      "↔Weighting\n",
      "change from\n",
      "last month\n",
      "– Underweight  + Overweight  • Neutral \n",
      "↔ No change ↑ Increase ↓ DecreaseAllocation\n",
      "versus the\n",
      "benchmarkASSET ALLOCATION\n",
      "Equity Sector Views (cont.)\n",
      "US\n",
      "We remain cautious given the macroeconomic uncertainties \n",
      "and so choose not to take any large sector bets at this time. \n",
      "Instead, focus is on individual company earnings resilience \n",
      "from a bottom-up perspective. We are underweight cyclical \n",
      "sectors where there is an unfavourable risk-reward profile, \n",
      "such as banks, heavy industrials and real estate. There have \n",
      "been selective additions to exposure in areas that were first \n",
      "impacted by the downturn and subsequently likely to be the \n",
      "first to recover, including semiconductors, digital advertising \n",
      "and housing.  \n",
      "Asia ex-Japan\n",
      "We maintain our overweight position in Asia ex-Japan. Within \n",
      "the region we maintain a relatively small overweight to \n",
      "China, where there is patchy economic recovery momentum \n",
      "but an improvement in earnings expectations. We are neutral \n",
      "on India, where economic momentum is robust. We note that \n",
      "there is particular strength in property as well as public and \n",
      "private capital expenditure, while there has been some \n",
      "consumer weakening. Within IT, the cycle has likely bottomed \n",
      "in areas such as memory, but other areas remain in a \n",
      "downtrend.\n",
      "No changes were made to our alternatives exposure this\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "versus the\n",
      "benchmark\n",
      "Equity Sector Views\n",
      "UK\n",
      "Industrials is the largest sector overweight within UK stocks, \n",
      "taking advantage of the de-rating seen across the sector to \n",
      "pick up quality companies. We favour more internationally \n",
      "exposed companies in the sector over those more reliant on \n",
      "domestic UK business. \n",
      "We have continued to add to utilities to boost defensive \n",
      "holdings in anticipation of a further weakening in the \n",
      "macroeconomic outlook for the UK. Regulatory uncertainty \n",
      "has reduced in recent months with clarity provided on \n",
      "windfall taxes, earnings resilience remains attractive in an \n",
      "inflationary environment, renewable transition programs are \n",
      "being accelerated and peaking bond yields should prove \n",
      "supportive for the sector.The consumer staples sector has demonstrated resilient \n",
      "earnings through this period of high inflation as it has been \n",
      "able to price ahead of rising costs in raw materials and labour \n",
      "while also keeping volumes stable. However, recent earnings \n",
      "have shown a shift in price elasticities, with several \n",
      "companies reporting weaker volumes and offering more \n",
      "cautious guidance for the future. With this in mind, we remain \n",
      "underweight in UK consumer staples.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "in areas such as memory, but other areas remain in a \n",
      "downtrend.\n",
      "No changes were made to our alternatives exposure this \n",
      "month. We remain cautious on the real estate sector owing \n",
      "to liquidity concerns. Commodity positioning is neutral with \n",
      "our focus being on gold exposure. While oil markets had a \n",
      "small pick-up after the OPEC decision to cut production the \n",
      "impact has been more muted than what was initially \n",
      "expected by markets.  \n",
      "Within hedge funds, heightened volatility stemming from \n",
      "uncertainty in inflation and rates should be supportive for \n",
      "equity market neutral managers. Similarly, commodity \n",
      "trading advisor strategies are preferred in the context of \n",
      "more market volatility. Europe\n",
      "Given headwinds for the European economy in the second \n",
      "half of the year, we are reducing equity risk in the region, by \n",
      "taking profits and moving to a neutral position. Within \n",
      "sectors, we have reduced our financials exposure, where we \n",
      "are now underweight with a focus on banks and insurance. \n",
      "We see limited scope for further earnings upgrades on net \n",
      "interest income/investment yields as terminal rate \n",
      "expectations in Europe have declined. Provisions and \n",
      "liquidity risks, primarily related to real estate, cannot be \n",
      "overlooked. We increased exposure to communication \n",
      "services, consumer staples, healthcare and technology \n",
      "sectors, having an overweight position in all of these \n",
      "sectors, focusing capital on the highest quality, most \n",
      "defensive parts of the European market.\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "571d4e79-3e33-4d16-817f-fee8e516d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist the vector DB for RAG\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bab50c-7f27-4a9a-8a1d-6b94ad62e5d1",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bf8700b-1bfb-46d4-8810-dca19c3928ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trucvietle/miniforge3/envs/llm-env/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Invoke the LLM\n",
    "llm_name = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(model_name=llm_name, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09b20f03-b1bc-4407-986b-14f76baca4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create QA chain and prompt template\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build the prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "# Run the chain\n",
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7a13303-e863-4572-8483-e840d8dd031c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trucvietle/miniforge3/envs/llm-env/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The house view is to maintain a moderate overweight in both equities and bonds, with adjustments in the allocation within asset classes. Within equities, there is a trimming of the overweight in Asian equities and a reduction in exposure to European markets. In fixed income, longer-dated government bonds and local currency emerging market debt are seen as attractive.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question = \"What is the main topic of this document?\"\n",
    "# question = \"What industry sectors are recommended for stocks?\"\n",
    "question = \"What is the house view between stocks and bonds?\"\n",
    "\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a41095db-0e05-4274-8b5c-c59b93a74c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result[\"source_documents\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "066d411f-20a7-4327-8f6f-eb4af286274a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The document suggests that the US dollar is expected to weaken in the second half of the year due to interest rate trends in Europe and the UK. Additionally, the document indicates an increase in exposure to emerging market local currency debt and a slight reduction in exposure to emerging market hard currency debt. Overall, the document suggests a strategic approach to currency allocation based on global economic conditions and central bank actions.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What does the document suggest about currencies?\"\n",
    "\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9869534a-e1d4-4c5b-8788-eebeb6213f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty_print_docs(result[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c17387b-0b9e-4038-bb77-a27be1f9f127",
   "metadata": {},
   "source": [
    "### Alternative: Compression retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d24d5ac2-2317-45b3-9e2d-809f776bc3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "# Wrap our vectorstore\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c63cb73-4b89-40ca-84a0-0f2ed1f97699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "to limit the riskiness of the portfolio, exposure to high yield bonds should be reduced in favour of investment grade corporate bonds.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "- Within fixed income, markets currently anticipate the Federal Reserve will cut rates by the end of the year as inflation is expected to decelerate. Therefore, in the context of a decelerating economy, declining inflation, and tight spreads in both US and European credit, we are reducing our exposure to high yield. Additionally, in response to changes in rate expectations and the recent increase in yields, portfolio duration is being increased to levels around 5-7 years by adding to sovereign bond exposure across currencies. Investment grade spreads remain attractive and therefore we maintain our overweight position.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "increased bond yields and the nearing of the end of monetary policy tightening make longer-dated government bonds attractive, including local currency emerging market debt.\n"
     ]
    }
   ],
   "source": [
    "question = \"What does the document suggest about bonds?\"\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "207614af-b5ec-4e8c-81f0-9dbefdf9ef09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The document suggests reducing exposure to high yield bonds in favor of investment grade corporate bonds, increasing portfolio duration with sovereign bond exposure, and finding attractive investment grade spreads.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=compression_retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n",
    "question = \"What does the document suggest about bonds?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40557923-c78e-4fb6-9711-9c0c69688ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /Users/trucvietle/Downloads/llm-models/mistral-7b-instruct-v0.1.Q6_K.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.1\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q6_K:  226 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q6_K\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 5.53 GiB (6.56 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.1\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
      "ggml_backend_metal_buffer_from_ptr: allocated buffer, size =   341.33 MiB, ( 1390.00 / 10922.67)\n",
      "llm_load_tensors: offloading 2 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 2/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  5666.09 MiB\n",
      "llm_load_tensors:      Metal buffer size =   341.32 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 8192\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1 Pro\n",
      "ggml_metal_init: picking default device: Apple M1 Pro\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/Users/trucvietle/miniforge3/envs/llm-env/lib/python3.12/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M1 Pro\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "llama_kv_cache_init:        CPU KV buffer size =   960.00 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =    64.00 MiB, ( 1455.00 / 10922.67)\n",
      "llama_kv_cache_init:      Metal KV buffer size =    64.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =     0.02 MiB, ( 1455.02 / 10922.67)\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =   556.02 MiB, ( 2011.02 / 10922.67)\n",
      "llama_new_context_with_model: graph splits (measure): 5\n",
      "llama_new_context_with_model:      Metal compute buffer size =   556.00 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   556.00 MiB\n"
     ]
    }
   ],
   "source": [
    "# Try on Mistral 7B model (offline)\n",
    "from llama_cpp import Llama\n",
    "\n",
    "model_path = \"/Users/trucvietle/Downloads/llm-models/mistral-7b-instruct-v0.1.Q6_K.gguf\"\n",
    "llm = Llama(model_path=model_path,\n",
    "            n_ctx=8192, n_batch=512,\n",
    "            n_threads=7, n_gpu_layers=2,\n",
    "            verbose=False, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e667cfe-3eda-420a-a4b4-691cdbd7bcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the question based on the context below.\n",
      "\n",
      "Context:\n",
      "to limit the riskiness of the portfolio, exposure to high yield bonds should be reduced in favour of investment grade corporate bonds.\n",
      "\n",
      "---\n",
      "\n",
      "- Within fixed income, markets currently anticipate the Federal Reserve will cut rates by the end of the year as inflation is expected to decelerate. Therefore, in the context of a decelerating economy, declining inflation, and tight spreads in both US and European credit, we are reducing our exposure to high yield. Additionally, in response to changes in rate expectations and the recent increase in yields, portfolio duration is being increased to levels around 5-7 years by adding to sovereign bond exposure across currencies. Investment grade spreads remain attractive and therefore we maintain our overweight position.\n",
      "\n",
      "---\n",
      "\n",
      "increased bond yields and the nearing of the end of monetary policy tightening make longer-dated government bonds attractive, including local currency emerging market debt.\n",
      "\n",
      "Question: What does the document suggest about bonds?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "query = \"What does the document suggest about bonds?\"\n",
    "\n",
    "contexts = [d.page_content for d in compressed_docs]\n",
    "\n",
    "prompt_start = (\n",
    "    \"Answer the question based on the context below.\\n\\n\"+\n",
    "    \"Context:\\n\"\n",
    ")\n",
    "\n",
    "prompt_end = (\n",
    "    f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
    ")\n",
    "\n",
    "prompt = (\n",
    "    prompt_start + \"\\n\\n---\\n\\n\".join(contexts) + \n",
    "    prompt_end\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b73106f8-f19c-4954-962f-39c6aa0795cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The document suggests that in the context of a decelerating economy, declining inflation, and tight spreads in both US and European credit, reducing exposure to high yield bonds should be considered in favor of investment grade corporate bonds. Additionally, it suggests that longer-dated government bonds, including local currency emerging market debt, are attractive due to increased bond yields and the nearing of the end of monetary policy tightening.\n"
     ]
    }
   ],
   "source": [
    "output = llm(prompt, echo=True, stream=False, max_tokens=4096)\n",
    "\n",
    "output_str = output[\"choices\"][0][\"text\"].replace(prompt, \"\")\n",
    "print(output_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e308a395-c762-4bd8-8211-6cf764eb572a",
   "metadata": {},
   "source": [
    "## Create a chatbot!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb78560-aa47-4d78-91b1-66aa92c3e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn  # GUI\n",
    "pn.extension()\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612301d1-aea1-41a7-afc0-9f68aaf04c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# # Invoke the LLM\n",
    "# llm_name = \"gpt-3.5-turbo\"\n",
    "# llm = ChatOpenAI(model_name=llm_name, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0490753-9ab2-4f15-9ef3-b7ed2735781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db(file, chain_type, k):\n",
    "    \n",
    "    # load documents\n",
    "    loader = PyPDFLoader(file)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # split documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # define embedding\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "    # create vector database from data\n",
    "    db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "    \n",
    "    # define retriever\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "    \n",
    "    # create a chatbot chain. Memory is managed externally.\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=llm_name, temperature=0), \n",
    "        chain_type=chain_type, \n",
    "        retriever=retriever, \n",
    "        return_source_documents=True,\n",
    "        return_generated_question=True,\n",
    "    )\n",
    "    \n",
    "    return qa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b597e7fc-15fb-4b63-ab12-463778e1a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import param\n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "    chat_history = param.List([])\n",
    "    answer = param.String(\"\")\n",
    "    db_query  = param.String(\"\")\n",
    "    db_response = param.List([])\n",
    "    \n",
    "    def __init__(self,  **params):\n",
    "        super(cbfs, self).__init__( **params)\n",
    "        self.panels = []\n",
    "        # self.loaded_file = \"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"\n",
    "        self.loaded_file = \"../docs/Inview_June_2023.pdfInview_June_2023.pdf\"\n",
    "        self.qa = load_db(self.loaded_file, \"stuff\", 4)\n",
    "    \n",
    "    def call_load_db(self, count):\n",
    "        if count == 0 or file_input.value is None:  # init or no file specified :\n",
    "            return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "        else:\n",
    "            file_input.save(\"temp.pdf\")  # local copy\n",
    "            self.loaded_file = file_input.filename\n",
    "            button_load.button_style=\"outline\"\n",
    "            self.qa = load_db(\"temp.pdf\", \"stuff\", 4)\n",
    "            button_load.button_style=\"solid\"\n",
    "            \n",
    "        self.clr_history()\n",
    "        return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "\n",
    "    def convchain(self, query):\n",
    "        if not query:\n",
    "            return pn.WidgetBox(pn.Row('User:', pn.pane.Markdown(\"\", width=600)), scroll=True)\n",
    "        result = self.qa({\"question\": query, \"chat_history\": self.chat_history})\n",
    "        self.chat_history.extend([(query, result[\"answer\"])])\n",
    "        self.db_query = result[\"generated_question\"]\n",
    "        self.db_response = result[\"source_documents\"]\n",
    "        self.answer = result['answer'] \n",
    "        self.panels.extend([\n",
    "            pn.Row('User:', pn.pane.Markdown(query, width=600)),\n",
    "            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=600, style={'background-color': '#F6F6F6'}))\n",
    "        ])\n",
    "        \n",
    "        inp.value = ''  #clears loading indicator when cleared\n",
    "        return pn.WidgetBox(*self.panels,scroll=True)\n",
    "\n",
    "    @param.depends('db_query ', )\n",
    "    def get_lquest(self):\n",
    "        if not self.db_query :\n",
    "            return pn.Column(\n",
    "                pn.Row(pn.pane.Markdown(f\"Last question to DB:\", styles={'background-color': '#F6F6F6'})),\n",
    "                pn.Row(pn.pane.Str(\"no DB accesses so far\"))\n",
    "            )\n",
    "        return pn.Column(\n",
    "            pn.Row(pn.pane.Markdown(f\"DB query:\", styles={'background-color': '#F6F6F6'})),\n",
    "            pn.pane.Str(self.db_query )\n",
    "        )\n",
    "\n",
    "    @param.depends('db_response', )\n",
    "    def get_sources(self):\n",
    "        if not self.db_response:\n",
    "            return \n",
    "        rlist=[pn.Row(pn.pane.Markdown(f\"Result of DB lookup:\", styles={'background-color': '#F6F6F6'}))]\n",
    "        for doc in self.db_response:\n",
    "            rlist.append(pn.Row(pn.pane.Str(doc)))\n",
    "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "\n",
    "    @param.depends('convchain', 'clr_history') \n",
    "    def get_chats(self):\n",
    "        if not self.chat_history:\n",
    "            return pn.WidgetBox(pn.Row(pn.pane.Str(\"No History Yet\")), width=600, scroll=True)\n",
    "        rlist=[pn.Row(pn.pane.Markdown(f\"Current Chat History variable\", styles={'background-color': '#F6F6F6'}))]\n",
    "        for exchange in self.chat_history:\n",
    "            rlist.append(pn.Row(pn.pane.Str(exchange)))\n",
    "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "\n",
    "    def clr_history(self,count=0):\n",
    "        self.chat_history = []\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f389819a-c19f-491d-a696-b656d1e33e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chatbot\n",
    "cb = cbfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1e1f49-f3c6-4e32-ac95-c9c5e7942cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the functions\n",
    "# filename = \"../docs/Inview_June_2023.pdfInview_June_2023.pdf\"\n",
    "# qa = load_db(filename, \"stuff\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398ce2e-b679-41ec-b0a0-1451ad4df4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the panels\n",
    "file_input = pn.widgets.FileInput(accept='.pdf')\n",
    "button_load = pn.widgets.Button(name=\"Load DB\", button_type='primary')\n",
    "button_clearhistory = pn.widgets.Button(name=\"Clear History\", button_type='warning')\n",
    "button_clearhistory.on_click(cb.clr_history)\n",
    "inp = pn.widgets.TextInput( placeholder='Enter text here…')\n",
    "\n",
    "bound_button_load = pn.bind(cb.call_load_db, button_load.param.clicks)\n",
    "conversation = pn.bind(cb.convchain, inp) \n",
    "\n",
    "jpg_pane = pn.pane.Image( './img/convchain.jpg')\n",
    "\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(conversation,  loading_indicator=True, height=300),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "tab2= pn.Column(\n",
    "    pn.panel(cb.get_lquest),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(cb.get_sources ),\n",
    ")\n",
    "tab3= pn.Column(\n",
    "    pn.panel(cb.get_chats),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "tab4=pn.Column(\n",
    "    pn.Row( file_input, button_load, bound_button_load),\n",
    "    pn.Row( button_clearhistory, pn.pane.Markdown(\"Clears chat history. Can use to start a new topic\" )),\n",
    "    pn.layout.Divider(),\n",
    "    pn.Row(jpg_pane.clone(width=400))\n",
    ")\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown('# ChatWithYourData_Bot')),\n",
    "    pn.Tabs(('Conversation', tab1), ('Database', tab2), ('Chat History', tab3),('Configure', tab4))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd43af3-5fad-427b-a28d-312d67a341ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd36f3-2038-4960-9d98-ba9ea07e9281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
